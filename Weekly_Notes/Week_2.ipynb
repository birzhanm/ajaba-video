{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "F4KRFW5AXTcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Networks\n",
        "This note introduced convolutional neural networks, commonly referred as CNN, and provides us with an instance of digit recognition problem to be solved with CNN's. This note contains two parts:\n",
        "1. Introduction to CNN's\n",
        "2. Example of using CNN's\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DPDX43D2lDne"
      },
      "cell_type": "markdown",
      "source": [
        "##Introduction to CNNs\n",
        "Convolutional neural network is based on idea of working with patches or neighborhoods, rather than the whole object. For instance if we are given an image of size 224x224, and we wish to all pixels at once as inputs then we have $224\\times 224 \\simeq 40,000$ inputs. Assuming that the next layer of neural network contains 1000 nodes, we have around $40,000\\times 1000 =40,000,000$ weight parameters for the first layer alone. This is a huge number. So, in order to decrease number of parameters that we are working on, one could consider not all pixel, but neighborhoods of pixels, say 5x5 square pixels, commonly referred as filters. This is just one of the possible motivations behind CNN's, there are many more. Let us learn more about Convolutional Neural Networks from the following sources:\n",
        "* <a href=\"https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/\">A Beginner's Guide To Understanding Convolutional Neural Networks (Blog Post by Adit Deshpande)</a>\n",
        "* <a href=\"https://www.youtube.com/watch?v=FTr3n7uBIuE\">Convolutional Neural Networks - The Math of Intelligence (Youtube Video by Siraj Raval)</a>"
      ]
    },
    {
      "metadata": {
        "id": "EMdi6Vd_lvXL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Example of Using CNN\n",
        "We are going to be building CNN based models for written digit recognition using a well-known MNIST dataset (<a href=\"http://yann.lecun.com/exdb/mnist/\">Homepage</a> of MNIST Dataset). Here is an overview of this dataset.\n",
        "1. Gray images of handwritten digits of size 28x28 pixels.\n",
        "1. Dataset contains 60,000 images in total, out of which 50,000 are used for training and 10,000 are used for testing."
      ]
    },
    {
      "metadata": {
        "id": "wNOMBHz4XbSo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Digit Recognition based on MNIST Dataset\n",
        "Our strategy:\n",
        "We will build progressively complex models starting from a very simple CNN, and utilizing more complex methods along the way. Here is a brief description of the models we are going to build:\n",
        "1. Simple CNN.\n",
        "1. Adding more layers.\n",
        "1. Adding more layers and dropout.\n",
        "1. Adding batch normalization (BN).\n",
        "1. Transfer Learning using ResNet-34. \n",
        "\n",
        "Before we proceed to building these models we need to prepare setup, i.e.\n",
        "1. Install and import necessary packages.\n",
        "1. Import and load MNIST dataset.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oIbJhVeppgw1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Setup Preparation"
      ]
    },
    {
      "metadata": {
        "id": "42jaVSCUXSss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# install and import torch and torchvision\n",
        "!pip install -q torch==1.0.0 torchvision\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gFANaUW8ZAOV",
        "colab_type": "code",
        "outputId": "9d078dab-e4e0-40e5-afbd-78e984033f45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1476
        }
      },
      "cell_type": "code",
      "source": [
        "# download and prepare data\n",
        "# set a manual seed for reproducibility of results.\n",
        "torch.manual_seed(7)\n",
        "# set a batch size for training models\n",
        "batch_size = 8\n",
        "\n",
        "# define transform on a dataset\n",
        "# the values for mean and standard deviation for MNIST dataset is from 'https://nextjournal.com/gkoehler/pytorch-mnist'.\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
        "# load MNIST data available in torchvision\n",
        "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# prepare batches for both train_set and test_set\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# let us look at some of the training images\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#roll batches\n",
        "batches = enumerate(train_loader)\n",
        "batch_id, (images, labels) = next(batches)\n",
        "\n",
        "print(images)\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(8):\n",
        "  plt.subplot(3,4,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(images[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground truth: {}\".format(labels[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 7660965.08it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 125126.85it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2056536.62it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 47346.44it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
            "\n",
            "\n",
            "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          ...,\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
            "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEACAYAAAATNRQCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 8 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_O_bSotSpZ4q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Constructing models\n",
        "###Simple CNN\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "O3FCOt-ChamZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# simple CNN\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_V1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_V1,self).__init__()\n",
        "    self.conv = nn.Conv2d(1,3,3)\n",
        "    self.fc = nn.Linear(3*26*26,10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv(x))\n",
        "    x = x.view(-1, 3*26*26)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cidBr_Glr-bp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Adding More Layers"
      ]
    },
    {
      "metadata": {
        "id": "Dzp6RWXjRqAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adding more layers\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_V2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_V2,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,3,3)\n",
        "    self.conv2 = nn.Conv2d(3,6,3)\n",
        "    self.fc1 = nn.Linear(6*24*24,100)\n",
        "    self.fc2 = nn.Linear(100,10)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = x.view(-1, 6*24*24)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kP2WvNNoskhr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Adding More Layers and Dropout Layers"
      ]
    },
    {
      "metadata": {
        "id": "5qwi1x5ETDhd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# adding more layers and dropout\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_V3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_V3,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,3,3)\n",
        "    self.conv2 = nn.Conv2d(3,6,3)\n",
        "    self.conv3 = nn.Conv2d(6,15,3)\n",
        "    self.conv3_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(15*22*22,100)\n",
        "    self.fc1_drop = nn.Dropout()\n",
        "    self.fc2 = nn.Linear(100,10)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = self.conv3_drop(F.relu(self.conv3(x)))\n",
        "    x = x.view(-1, 15*22*22)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc1_drop(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4pXOlDSgs0mk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Adding More Layers and Batch Normalization"
      ]
    },
    {
      "metadata": {
        "id": "vPeXee3IWvgX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#adding more layers and batch normalization\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN_V4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_V4,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,3,3)\n",
        "    self.conv2 = nn.Conv2d(3,6,3)\n",
        "    self.conv3 = nn.Conv2d(6,15,3)\n",
        "    self.conv3_bn = nn.BatchNorm2d(15)\n",
        "    self.conv4 = nn.Conv2d(15,30,3)\n",
        "    self.conv4_bn = nn.BatchNorm2d(30)\n",
        "    self.conv4_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(30*20*20,500)\n",
        "    self.fc1_bn = nn.BatchNorm1d(500)\n",
        "    self.fc1_drop = nn.Dropout()\n",
        "    self.fc2 = nn.Linear(500,100)\n",
        "    self.fc2_drop = nn.Dropout()\n",
        "    self.fc3 = nn.Linear(100,10)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.relu(self.conv3_bn(self.conv3(x)))\n",
        "    x = self.conv4_bn(self.conv4(x))\n",
        "    x = self.conv4_drop(F.relu(x))\n",
        "    x = x.view(-1, 30*20*20)\n",
        "    x = self.fc1_bn(self.fc1(x))\n",
        "    x = self.fc1_drop(F.relu(x))\n",
        "    x = self.fc2_drop(F.relu(self.fc2(x)))\n",
        "    x = self.fc3(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOmNTkx0cWwx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Initiating and Training models\n"
      ]
    },
    {
      "metadata": {
        "id": "YE4tGGHOoYb9",
        "colab_type": "code",
        "outputId": "f07a554b-0231-4d6e-e7f5-69173cec265b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "# set up number of epochs\n",
        "epochs = 2\n",
        "\n",
        "# initiate models\n",
        "cnn_v1 = CNN_V1()\n",
        "cnn_v2 = CNN_V2()\n",
        "cnn_v3 = CNN_V3()\n",
        "cnn_v4 = CNN_V4()\n",
        "# let's do a single forward prop as a sanity check\n",
        "x = torch.rand(2,1,28,28)\n",
        "out_v1 = cnn_v1(x)\n",
        "out_v2 = cnn_v2(x)\n",
        "out_v3 = cnn_v3(x)\n",
        "out_v4 = cnn_v4(x)\n",
        "print(\"Output for V1: {}\".format(out_v1))\n",
        "print(\"Output for V2: {}\".format(out_v2))\n",
        "print(\"Output for V3: {}\".format(out_v3))\n",
        "print(\"Output for V4: {}\".format(out_v4))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output for V1: tensor([[ 0.0085, -0.0168, -0.0716,  0.0792, -0.0089,  0.2301, -0.0455,  0.0198,\n",
            "         -0.0403, -0.1368],\n",
            "        [-0.0423,  0.0502,  0.0599,  0.1415, -0.0176,  0.1306,  0.0133, -0.0314,\n",
            "         -0.0078, -0.1017]], grad_fn=<AddmmBackward>)\n",
            "Output for V2: tensor([[-0.0035, -0.0154, -0.1059, -0.0844, -0.0672,  0.0608, -0.1142, -0.1013,\n",
            "          0.0666, -0.0519],\n",
            "        [ 0.0190, -0.0110, -0.0748, -0.0729, -0.0999,  0.0602, -0.1179, -0.0700,\n",
            "          0.0731, -0.0595]], grad_fn=<AddmmBackward>)\n",
            "Output for V3: tensor([[ 0.0078,  0.0400, -0.0782,  0.0130, -0.1160,  0.1464,  0.1158, -0.0240,\n",
            "         -0.0310, -0.0739],\n",
            "        [ 0.0240, -0.0265, -0.0503,  0.0642, -0.1317,  0.0664,  0.0645, -0.0447,\n",
            "          0.0476, -0.0875]], grad_fn=<AddmmBackward>)\n",
            "Output for V4: tensor([[ 0.1563,  0.3090, -0.2973, -0.0944,  0.3865,  0.1968,  0.0800, -0.1160,\n",
            "         -0.2194, -0.0426],\n",
            "        [ 0.2680,  0.3580, -0.0408, -0.0794, -0.0037, -0.0838,  0.0067,  0.0455,\n",
            "          0.0963,  0.0199]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ra0Sem1pvqWN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "190fb063-3842-4447-ae4b-0142dacb4373"
      },
      "cell_type": "code",
      "source": [
        "# prepare GPU for training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5kTUsEdvysH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training cnn_v1"
      ]
    },
    {
      "metadata": {
        "id": "oMOd3NNpvyRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        },
        "outputId": "7a47f5a4-bf8c-4ed1-96dd-f8037b9a5b90"
      },
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_v1.parameters(), lr=0.001)\n",
        "\n",
        "# wrap the model into gpu\n",
        "cnn_v1.to(device)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = cnn_v1(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing statistics\n",
        "    running_loss += loss.item()\n",
        "    if i%200 == 199:\n",
        "      print('Epoch: {}, Batch: {} - Loss: {}'.format(epoch, i+1, running_loss/200))\n",
        "      running_loss = 0\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 200 - Loss: 0.09081409649923444\n",
            "Epoch: 0, Batch: 400 - Loss: 0.11412503485567868\n",
            "Epoch: 0, Batch: 600 - Loss: 0.09266440269071609\n",
            "Epoch: 0, Batch: 800 - Loss: 0.1019471222627908\n",
            "Epoch: 0, Batch: 1000 - Loss: 0.11093067368492485\n",
            "Epoch: 0, Batch: 1200 - Loss: 0.10419477491406724\n",
            "Epoch: 0, Batch: 1400 - Loss: 0.07562544176122174\n",
            "Epoch: 0, Batch: 1600 - Loss: 0.12293449342250824\n",
            "Epoch: 0, Batch: 1800 - Loss: 0.06379808757919818\n",
            "Epoch: 0, Batch: 2000 - Loss: 0.09311226944439113\n",
            "Epoch: 0, Batch: 2200 - Loss: 0.11067786226980388\n",
            "Epoch: 0, Batch: 2400 - Loss: 0.1136736636934802\n",
            "Epoch: 0, Batch: 2600 - Loss: 0.10104291468160227\n",
            "Epoch: 0, Batch: 2800 - Loss: 0.12839455345645548\n",
            "Epoch: 0, Batch: 3000 - Loss: 0.1235307343211025\n",
            "Epoch: 0, Batch: 3200 - Loss: 0.10038810547441245\n",
            "Epoch: 0, Batch: 3400 - Loss: 0.1072027302812785\n",
            "Epoch: 0, Batch: 3600 - Loss: 0.11966330540366471\n",
            "Epoch: 0, Batch: 3800 - Loss: 0.08808071171166375\n",
            "Epoch: 0, Batch: 4000 - Loss: 0.09791414052248001\n",
            "Epoch: 0, Batch: 4200 - Loss: 0.08546609935350716\n",
            "Epoch: 0, Batch: 4400 - Loss: 0.10616991826333105\n",
            "Epoch: 0, Batch: 4600 - Loss: 0.14477640174329282\n",
            "Epoch: 0, Batch: 4800 - Loss: 0.09860393441747874\n",
            "Epoch: 0, Batch: 5000 - Loss: 0.08758140294812619\n",
            "Epoch: 0, Batch: 5200 - Loss: 0.11014527338498738\n",
            "Epoch: 0, Batch: 5400 - Loss: 0.09761102423537522\n",
            "Epoch: 0, Batch: 5600 - Loss: 0.12558944312855602\n",
            "Epoch: 0, Batch: 5800 - Loss: 0.11782961420249194\n",
            "Epoch: 0, Batch: 6000 - Loss: 0.08086680391104892\n",
            "Epoch: 0, Batch: 6200 - Loss: 0.08815587823977694\n",
            "Epoch: 0, Batch: 6400 - Loss: 0.09003789730370045\n",
            "Epoch: 0, Batch: 6600 - Loss: 0.11370793779962696\n",
            "Epoch: 0, Batch: 6800 - Loss: 0.0835496646584943\n",
            "Epoch: 0, Batch: 7000 - Loss: 0.1043064797972329\n",
            "Epoch: 0, Batch: 7200 - Loss: 0.12847064316738396\n",
            "Epoch: 0, Batch: 7400 - Loss: 0.09610405007377266\n",
            "Epoch: 1, Batch: 200 - Loss: 0.1101603587390855\n",
            "Epoch: 1, Batch: 400 - Loss: 0.09047588332323357\n",
            "Epoch: 1, Batch: 600 - Loss: 0.0644484387151897\n",
            "Epoch: 1, Batch: 800 - Loss: 0.0848397900396958\n",
            "Epoch: 1, Batch: 1000 - Loss: 0.07754095482639968\n",
            "Epoch: 1, Batch: 1200 - Loss: 0.0773845179984346\n",
            "Epoch: 1, Batch: 1400 - Loss: 0.05563150640111417\n",
            "Epoch: 1, Batch: 1600 - Loss: 0.08571499053854495\n",
            "Epoch: 1, Batch: 1800 - Loss: 0.0829728006129153\n",
            "Epoch: 1, Batch: 2000 - Loss: 0.09660637323744595\n",
            "Epoch: 1, Batch: 2200 - Loss: 0.10730296048335732\n",
            "Epoch: 1, Batch: 2400 - Loss: 0.0703222028631717\n",
            "Epoch: 1, Batch: 2600 - Loss: 0.0830404720082879\n",
            "Epoch: 1, Batch: 2800 - Loss: 0.09881728597683832\n",
            "Epoch: 1, Batch: 3000 - Loss: 0.08933152751997113\n",
            "Epoch: 1, Batch: 3200 - Loss: 0.11089990493375808\n",
            "Epoch: 1, Batch: 3400 - Loss: 0.0900804854510352\n",
            "Epoch: 1, Batch: 3600 - Loss: 0.0900775180500932\n",
            "Epoch: 1, Batch: 3800 - Loss: 0.09353106102906167\n",
            "Epoch: 1, Batch: 4000 - Loss: 0.08795378003502265\n",
            "Epoch: 1, Batch: 4200 - Loss: 0.09794977213721723\n",
            "Epoch: 1, Batch: 4400 - Loss: 0.08434194247238339\n",
            "Epoch: 1, Batch: 4600 - Loss: 0.07505855299765245\n",
            "Epoch: 1, Batch: 4800 - Loss: 0.09147127450443804\n",
            "Epoch: 1, Batch: 5000 - Loss: 0.08110584852984175\n",
            "Epoch: 1, Batch: 5200 - Loss: 0.07883435983676464\n",
            "Epoch: 1, Batch: 5400 - Loss: 0.12208403783733957\n",
            "Epoch: 1, Batch: 5600 - Loss: 0.06565184060484171\n",
            "Epoch: 1, Batch: 5800 - Loss: 0.09585824887966737\n",
            "Epoch: 1, Batch: 6000 - Loss: 0.09774134980223607\n",
            "Epoch: 1, Batch: 6200 - Loss: 0.062025917295832185\n",
            "Epoch: 1, Batch: 6400 - Loss: 0.07286960075143725\n",
            "Epoch: 1, Batch: 6600 - Loss: 0.07642396835610271\n",
            "Epoch: 1, Batch: 6800 - Loss: 0.09839092647656798\n",
            "Epoch: 1, Batch: 7000 - Loss: 0.09169852335005999\n",
            "Epoch: 1, Batch: 7200 - Loss: 0.11035199049860239\n",
            "Epoch: 1, Batch: 7400 - Loss: 0.08385336629813538\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b9mD8ei7yABa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training cnn_v2"
      ]
    },
    {
      "metadata": {
        "id": "mhZO9S1TyEfO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        },
        "outputId": "3726422c-b229-4936-be8e-b945e8f57187"
      },
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_v2.parameters(), lr=0.001)\n",
        "\n",
        "# wrap the model into gpu\n",
        "cnn_v2.to(device)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = cnn_v2(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing statistics\n",
        "    running_loss += loss.item()\n",
        "    if i%200 == 199:\n",
        "      print('Epoch: {}, Batch: {} - Loss: {}'.format(epoch, i+1, running_loss/200))\n",
        "      running_loss = 0\n",
        "print('Finished Training')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 200 - Loss: 0.883667321279645\n",
            "Epoch: 0, Batch: 400 - Loss: 0.4388375504314899\n",
            "Epoch: 0, Batch: 600 - Loss: 0.32481169544160365\n",
            "Epoch: 0, Batch: 800 - Loss: 0.28674547746777534\n",
            "Epoch: 0, Batch: 1000 - Loss: 0.19105149634182453\n",
            "Epoch: 0, Batch: 1200 - Loss: 0.2466953592002392\n",
            "Epoch: 0, Batch: 1400 - Loss: 0.20379347242414952\n",
            "Epoch: 0, Batch: 1600 - Loss: 0.16668335787951946\n",
            "Epoch: 0, Batch: 1800 - Loss: 0.20847314141690731\n",
            "Epoch: 0, Batch: 2000 - Loss: 0.20358179554343223\n",
            "Epoch: 0, Batch: 2200 - Loss: 0.1410105687379837\n",
            "Epoch: 0, Batch: 2400 - Loss: 0.17072656661272048\n",
            "Epoch: 0, Batch: 2600 - Loss: 0.1644044318050146\n",
            "Epoch: 0, Batch: 2800 - Loss: 0.15318483404815197\n",
            "Epoch: 0, Batch: 3000 - Loss: 0.11057861983776092\n",
            "Epoch: 0, Batch: 3200 - Loss: 0.13759844742715358\n",
            "Epoch: 0, Batch: 3400 - Loss: 0.13041406877338887\n",
            "Epoch: 0, Batch: 3600 - Loss: 0.13798435360193254\n",
            "Epoch: 0, Batch: 3800 - Loss: 0.12675825141370298\n",
            "Epoch: 0, Batch: 4000 - Loss: 0.12077093489468098\n",
            "Epoch: 0, Batch: 4200 - Loss: 0.11435226820409299\n",
            "Epoch: 0, Batch: 4400 - Loss: 0.11147678762674332\n",
            "Epoch: 0, Batch: 4600 - Loss: 0.08511184327304364\n",
            "Epoch: 0, Batch: 4800 - Loss: 0.08680384807288646\n",
            "Epoch: 0, Batch: 5000 - Loss: 0.10726516358554364\n",
            "Epoch: 0, Batch: 5200 - Loss: 0.10339485332369805\n",
            "Epoch: 0, Batch: 5400 - Loss: 0.09153213366866111\n",
            "Epoch: 0, Batch: 5600 - Loss: 0.09695498697459698\n",
            "Epoch: 0, Batch: 5800 - Loss: 0.10785462409257889\n",
            "Epoch: 0, Batch: 6000 - Loss: 0.10499881654977798\n",
            "Epoch: 0, Batch: 6200 - Loss: 0.10323363903909921\n",
            "Epoch: 0, Batch: 6400 - Loss: 0.0757904053479433\n",
            "Epoch: 0, Batch: 6600 - Loss: 0.09452967084944248\n",
            "Epoch: 0, Batch: 6800 - Loss: 0.0807692489027977\n",
            "Epoch: 0, Batch: 7000 - Loss: 0.08729654252529144\n",
            "Epoch: 0, Batch: 7200 - Loss: 0.07493490487337112\n",
            "Epoch: 0, Batch: 7400 - Loss: 0.09689298328012227\n",
            "Epoch: 1, Batch: 200 - Loss: 0.05750666059553623\n",
            "Epoch: 1, Batch: 400 - Loss: 0.05063414976000786\n",
            "Epoch: 1, Batch: 600 - Loss: 0.07013264313340187\n",
            "Epoch: 1, Batch: 800 - Loss: 0.0676824190467596\n",
            "Epoch: 1, Batch: 1000 - Loss: 0.07816353522241115\n",
            "Epoch: 1, Batch: 1200 - Loss: 0.05668213903903961\n",
            "Epoch: 1, Batch: 1400 - Loss: 0.06615624506026506\n",
            "Epoch: 1, Batch: 1600 - Loss: 0.07154644995927811\n",
            "Epoch: 1, Batch: 1800 - Loss: 0.06738356456160545\n",
            "Epoch: 1, Batch: 2000 - Loss: 0.08170695684850215\n",
            "Epoch: 1, Batch: 2200 - Loss: 0.03844900615513325\n",
            "Epoch: 1, Batch: 2400 - Loss: 0.07362451680004596\n",
            "Epoch: 1, Batch: 2600 - Loss: 0.07064555436372758\n",
            "Epoch: 1, Batch: 2800 - Loss: 0.061313215792179104\n",
            "Epoch: 1, Batch: 3000 - Loss: 0.05638085376471281\n",
            "Epoch: 1, Batch: 3200 - Loss: 0.045397654473781586\n",
            "Epoch: 1, Batch: 3400 - Loss: 0.07756152503192425\n",
            "Epoch: 1, Batch: 3600 - Loss: 0.06836642317473889\n",
            "Epoch: 1, Batch: 3800 - Loss: 0.07977362655103207\n",
            "Epoch: 1, Batch: 4000 - Loss: 0.0470036468654871\n",
            "Epoch: 1, Batch: 4200 - Loss: 0.05148828864097595\n",
            "Epoch: 1, Batch: 4400 - Loss: 0.060470830164849755\n",
            "Epoch: 1, Batch: 4600 - Loss: 0.06459752716124058\n",
            "Epoch: 1, Batch: 4800 - Loss: 0.05766242697834969\n",
            "Epoch: 1, Batch: 5000 - Loss: 0.053652362525463106\n",
            "Epoch: 1, Batch: 5200 - Loss: 0.0745606604963541\n",
            "Epoch: 1, Batch: 5400 - Loss: 0.05853283166885376\n",
            "Epoch: 1, Batch: 5600 - Loss: 0.06282562918961049\n",
            "Epoch: 1, Batch: 5800 - Loss: 0.0342495246976614\n",
            "Epoch: 1, Batch: 6000 - Loss: 0.0678474898636341\n",
            "Epoch: 1, Batch: 6200 - Loss: 0.07009837657213211\n",
            "Epoch: 1, Batch: 6400 - Loss: 0.07367349039763212\n",
            "Epoch: 1, Batch: 6600 - Loss: 0.04327300015836954\n",
            "Epoch: 1, Batch: 6800 - Loss: 0.056794823035597804\n",
            "Epoch: 1, Batch: 7000 - Loss: 0.059081652462482454\n",
            "Epoch: 1, Batch: 7200 - Loss: 0.0667970748245716\n",
            "Epoch: 1, Batch: 7400 - Loss: 0.05453124575316906\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dt_MGZdfy16N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training cnn_v3"
      ]
    },
    {
      "metadata": {
        "id": "6LVimmnpy5LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        },
        "outputId": "775899ab-410b-4260-d211-894736df8362"
      },
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_v3.parameters(), lr=0.001)\n",
        "\n",
        "# wrap the model into gpu\n",
        "cnn_v3.to(device)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = cnn_v3(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing statistics\n",
        "    running_loss += loss.item()\n",
        "    if i%200 == 199:\n",
        "      print('Epoch: {}, Batch: {} - Loss: {}'.format(epoch, i+1, running_loss/200))\n",
        "      running_loss = 0\n",
        "print('Finished Training')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 200 - Loss: 1.5200825870037078\n",
            "Epoch: 0, Batch: 400 - Loss: 0.8481321977823972\n",
            "Epoch: 0, Batch: 600 - Loss: 0.6604422853142023\n",
            "Epoch: 0, Batch: 800 - Loss: 0.5952262209355831\n",
            "Epoch: 0, Batch: 1000 - Loss: 0.49028256177902224\n",
            "Epoch: 0, Batch: 1200 - Loss: 0.5170204756408929\n",
            "Epoch: 0, Batch: 1400 - Loss: 0.4325488954782486\n",
            "Epoch: 0, Batch: 1600 - Loss: 0.40945327691733835\n",
            "Epoch: 0, Batch: 1800 - Loss: 0.3908542595803738\n",
            "Epoch: 0, Batch: 2000 - Loss: 0.4075993803143501\n",
            "Epoch: 0, Batch: 2200 - Loss: 0.45056242421269416\n",
            "Epoch: 0, Batch: 2400 - Loss: 0.38851805932819844\n",
            "Epoch: 0, Batch: 2600 - Loss: 0.35695792131125925\n",
            "Epoch: 0, Batch: 2800 - Loss: 0.3348085116967559\n",
            "Epoch: 0, Batch: 3000 - Loss: 0.31987698391079905\n",
            "Epoch: 0, Batch: 3200 - Loss: 0.30306055933237075\n",
            "Epoch: 0, Batch: 3400 - Loss: 0.30765617623925207\n",
            "Epoch: 0, Batch: 3600 - Loss: 0.3252751121670008\n",
            "Epoch: 0, Batch: 3800 - Loss: 0.3324121344089508\n",
            "Epoch: 0, Batch: 4000 - Loss: 0.27395688626915216\n",
            "Epoch: 0, Batch: 4200 - Loss: 0.2999493692070246\n",
            "Epoch: 0, Batch: 4400 - Loss: 0.29205745965242386\n",
            "Epoch: 0, Batch: 4600 - Loss: 0.3320876057446003\n",
            "Epoch: 0, Batch: 4800 - Loss: 0.27772365886718037\n",
            "Epoch: 0, Batch: 5000 - Loss: 0.27317395210266116\n",
            "Epoch: 0, Batch: 5200 - Loss: 0.3033998540788889\n",
            "Epoch: 0, Batch: 5400 - Loss: 0.26147700801491736\n",
            "Epoch: 0, Batch: 5600 - Loss: 0.26907571997493507\n",
            "Epoch: 0, Batch: 5800 - Loss: 0.24693496458232403\n",
            "Epoch: 0, Batch: 6000 - Loss: 0.2746966005861759\n",
            "Epoch: 0, Batch: 6200 - Loss: 0.2948372111469507\n",
            "Epoch: 0, Batch: 6400 - Loss: 0.2556857283040881\n",
            "Epoch: 0, Batch: 6600 - Loss: 0.23777719408273698\n",
            "Epoch: 0, Batch: 6800 - Loss: 0.26445514619350435\n",
            "Epoch: 0, Batch: 7000 - Loss: 0.26430434815585613\n",
            "Epoch: 0, Batch: 7200 - Loss: 0.249961449354887\n",
            "Epoch: 0, Batch: 7400 - Loss: 0.28837267234921454\n",
            "Epoch: 1, Batch: 200 - Loss: 0.21558111190795898\n",
            "Epoch: 1, Batch: 400 - Loss: 0.22571643356233836\n",
            "Epoch: 1, Batch: 600 - Loss: 0.1976264362409711\n",
            "Epoch: 1, Batch: 800 - Loss: 0.20639129552990199\n",
            "Epoch: 1, Batch: 1000 - Loss: 0.2364143368601799\n",
            "Epoch: 1, Batch: 1200 - Loss: 0.22303664181381463\n",
            "Epoch: 1, Batch: 1400 - Loss: 0.2283665094152093\n",
            "Epoch: 1, Batch: 1600 - Loss: 0.22259596582502128\n",
            "Epoch: 1, Batch: 1800 - Loss: 0.23103429112583398\n",
            "Epoch: 1, Batch: 2000 - Loss: 0.21802577201277018\n",
            "Epoch: 1, Batch: 2200 - Loss: 0.270738661698997\n",
            "Epoch: 1, Batch: 2400 - Loss: 0.21900603644549846\n",
            "Epoch: 1, Batch: 2600 - Loss: 0.20379753541201354\n",
            "Epoch: 1, Batch: 2800 - Loss: 0.2060849617421627\n",
            "Epoch: 1, Batch: 3000 - Loss: 0.22396039329469203\n",
            "Epoch: 1, Batch: 3200 - Loss: 0.23768400423228742\n",
            "Epoch: 1, Batch: 3400 - Loss: 0.2257091987505555\n",
            "Epoch: 1, Batch: 3600 - Loss: 0.2251416989043355\n",
            "Epoch: 1, Batch: 3800 - Loss: 0.20427877977490425\n",
            "Epoch: 1, Batch: 4000 - Loss: 0.24248632475733756\n",
            "Epoch: 1, Batch: 4200 - Loss: 0.20017533976584673\n",
            "Epoch: 1, Batch: 4400 - Loss: 0.19643671423196793\n",
            "Epoch: 1, Batch: 4600 - Loss: 0.20609849687665702\n",
            "Epoch: 1, Batch: 4800 - Loss: 0.23099027410149575\n",
            "Epoch: 1, Batch: 5000 - Loss: 0.181700870282948\n",
            "Epoch: 1, Batch: 5200 - Loss: 0.17722648780792952\n",
            "Epoch: 1, Batch: 5400 - Loss: 0.19684280354529618\n",
            "Epoch: 1, Batch: 5600 - Loss: 0.1821907585673034\n",
            "Epoch: 1, Batch: 5800 - Loss: 0.23049892477691172\n",
            "Epoch: 1, Batch: 6000 - Loss: 0.2177052229642868\n",
            "Epoch: 1, Batch: 6200 - Loss: 0.1901815817505121\n",
            "Epoch: 1, Batch: 6400 - Loss: 0.1847775635123253\n",
            "Epoch: 1, Batch: 6600 - Loss: 0.1883955805003643\n",
            "Epoch: 1, Batch: 6800 - Loss: 0.2254520555958152\n",
            "Epoch: 1, Batch: 7000 - Loss: 0.1749595887027681\n",
            "Epoch: 1, Batch: 7200 - Loss: 0.19092316402122378\n",
            "Epoch: 1, Batch: 7400 - Loss: 0.22863821133971216\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p9cgycTzzEV9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training cnn_v4"
      ]
    },
    {
      "metadata": {
        "id": "Sck9dfWgzHQr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1303
        },
        "outputId": "07450f4d-17d7-43d8-ec84-ac223ea6f918"
      },
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(cnn_v4.parameters(), lr=0.001)\n",
        "\n",
        "# wrap the model into gpu\n",
        "cnn_v4.to(device)\n",
        "\n",
        "# training loop\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = cnn_v4(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing statistics\n",
        "    running_loss += loss.item()\n",
        "    if i%200 == 199:\n",
        "      print('Epoch: {}, Batch: {} - Loss: {}'.format(epoch, i+1, running_loss/200))\n",
        "      running_loss = 0\n",
        "print('Finished Training')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Batch: 200 - Loss: 1.4571962144970894\n",
            "Epoch: 0, Batch: 400 - Loss: 0.7247501852363348\n",
            "Epoch: 0, Batch: 600 - Loss: 0.5987073288857937\n",
            "Epoch: 0, Batch: 800 - Loss: 0.5820595023781061\n",
            "Epoch: 0, Batch: 1000 - Loss: 0.4949829129874706\n",
            "Epoch: 0, Batch: 1200 - Loss: 0.4551551349461079\n",
            "Epoch: 0, Batch: 1400 - Loss: 0.46693351328372956\n",
            "Epoch: 0, Batch: 1600 - Loss: 0.4756366084516048\n",
            "Epoch: 0, Batch: 1800 - Loss: 0.4104981115460396\n",
            "Epoch: 0, Batch: 2000 - Loss: 0.4511081735789776\n",
            "Epoch: 0, Batch: 2200 - Loss: 0.3598404933512211\n",
            "Epoch: 0, Batch: 2400 - Loss: 0.39632243938744066\n",
            "Epoch: 0, Batch: 2600 - Loss: 0.39074073016643524\n",
            "Epoch: 0, Batch: 2800 - Loss: 0.377101222127676\n",
            "Epoch: 0, Batch: 3000 - Loss: 0.37430446207523344\n",
            "Epoch: 0, Batch: 3200 - Loss: 0.371715896576643\n",
            "Epoch: 0, Batch: 3400 - Loss: 0.33163882471621037\n",
            "Epoch: 0, Batch: 3600 - Loss: 0.3553440885990858\n",
            "Epoch: 0, Batch: 3800 - Loss: 0.3547813042253256\n",
            "Epoch: 0, Batch: 4000 - Loss: 0.32066049180924894\n",
            "Epoch: 0, Batch: 4200 - Loss: 0.3316214992851019\n",
            "Epoch: 0, Batch: 4400 - Loss: 0.3365517692267895\n",
            "Epoch: 0, Batch: 4600 - Loss: 0.3554582525789738\n",
            "Epoch: 0, Batch: 4800 - Loss: 0.33454698339104655\n",
            "Epoch: 0, Batch: 5000 - Loss: 0.3432924484461546\n",
            "Epoch: 0, Batch: 5200 - Loss: 0.31886585004627704\n",
            "Epoch: 0, Batch: 5400 - Loss: 0.30328690484166143\n",
            "Epoch: 0, Batch: 5600 - Loss: 0.31376527741551397\n",
            "Epoch: 0, Batch: 5800 - Loss: 0.34353835731744764\n",
            "Epoch: 0, Batch: 6000 - Loss: 0.3187672697752714\n",
            "Epoch: 0, Batch: 6200 - Loss: 0.3187757898122072\n",
            "Epoch: 0, Batch: 6400 - Loss: 0.3678596369177103\n",
            "Epoch: 0, Batch: 6600 - Loss: 0.30090483620762826\n",
            "Epoch: 0, Batch: 6800 - Loss: 0.2942886532843113\n",
            "Epoch: 0, Batch: 7000 - Loss: 0.2742636025696993\n",
            "Epoch: 0, Batch: 7200 - Loss: 0.3214427825808525\n",
            "Epoch: 0, Batch: 7400 - Loss: 0.31731412924826147\n",
            "Epoch: 1, Batch: 200 - Loss: 0.2523008596152067\n",
            "Epoch: 1, Batch: 400 - Loss: 0.28933610290288925\n",
            "Epoch: 1, Batch: 600 - Loss: 0.2845643801242113\n",
            "Epoch: 1, Batch: 800 - Loss: 0.30083071991801263\n",
            "Epoch: 1, Batch: 1000 - Loss: 0.2642586408555508\n",
            "Epoch: 1, Batch: 1200 - Loss: 0.30895790196955203\n",
            "Epoch: 1, Batch: 1400 - Loss: 0.28674642339348794\n",
            "Epoch: 1, Batch: 1600 - Loss: 0.2612266153842211\n",
            "Epoch: 1, Batch: 1800 - Loss: 0.279907456561923\n",
            "Epoch: 1, Batch: 2000 - Loss: 0.2633266052976251\n",
            "Epoch: 1, Batch: 2200 - Loss: 0.2774137045443058\n",
            "Epoch: 1, Batch: 2400 - Loss: 0.26438004299998286\n",
            "Epoch: 1, Batch: 2600 - Loss: 0.2819673452153802\n",
            "Epoch: 1, Batch: 2800 - Loss: 0.26179450113326314\n",
            "Epoch: 1, Batch: 3000 - Loss: 0.2946986719965935\n",
            "Epoch: 1, Batch: 3200 - Loss: 0.2918228391930461\n",
            "Epoch: 1, Batch: 3400 - Loss: 0.2593751685321331\n",
            "Epoch: 1, Batch: 3600 - Loss: 0.254902826808393\n",
            "Epoch: 1, Batch: 3800 - Loss: 0.23383994966745378\n",
            "Epoch: 1, Batch: 4000 - Loss: 0.23560262136161328\n",
            "Epoch: 1, Batch: 4200 - Loss: 0.2862836753576994\n",
            "Epoch: 1, Batch: 4400 - Loss: 0.2728835045918822\n",
            "Epoch: 1, Batch: 4600 - Loss: 0.28760242264717817\n",
            "Epoch: 1, Batch: 4800 - Loss: 0.24825041308999063\n",
            "Epoch: 1, Batch: 5000 - Loss: 0.2905498007684946\n",
            "Epoch: 1, Batch: 5200 - Loss: 0.28472285740077496\n",
            "Epoch: 1, Batch: 5400 - Loss: 0.24764988340437413\n",
            "Epoch: 1, Batch: 5600 - Loss: 0.22071427889168263\n",
            "Epoch: 1, Batch: 5800 - Loss: 0.2869170557335019\n",
            "Epoch: 1, Batch: 6000 - Loss: 0.24803036950528623\n",
            "Epoch: 1, Batch: 6200 - Loss: 0.2668679093942046\n",
            "Epoch: 1, Batch: 6400 - Loss: 0.22598514080047608\n",
            "Epoch: 1, Batch: 6600 - Loss: 0.24275854289531706\n",
            "Epoch: 1, Batch: 6800 - Loss: 0.2738579712063074\n",
            "Epoch: 1, Batch: 7000 - Loss: 0.26596117481589315\n",
            "Epoch: 1, Batch: 7200 - Loss: 0.2611768887937069\n",
            "Epoch: 1, Batch: 7400 - Loss: 0.25300518326461313\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HDj2p4Qd03Ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Testing models"
      ]
    },
    {
      "metadata": {
        "id": "pc3I4RSz1A3r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing cnn_v1"
      ]
    },
    {
      "metadata": {
        "id": "bkCCsZwxCSsq",
        "colab_type": "code",
        "outputId": "2c92c0a8-48a3-4c02-dac9-f94a59b50a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = cnn_v1(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of cnn_v1 on 10,000 test images is {}'.format(correct/total))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of cnn_v1 on 10,000 test images is 0.9662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hyNC9QrV9vYt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing cnn_v2"
      ]
    },
    {
      "metadata": {
        "id": "U1AqvA_W9ycf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "104ffdac-3bc3-44ea-9354-07d4c037237c"
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = cnn_v2(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of cnn_v2 on 10,000 test images is {}'.format(correct/total))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of cnn_v2 on 10,000 test images is 0.9786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pvElM-bB-GNt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing cnn_v3"
      ]
    },
    {
      "metadata": {
        "id": "LqLBSGnd-JgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3dd8adc-1a50-4d68-c079-52d8b6e291ab"
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = cnn_v3(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of cnn_v3 on 10,000 test images is {}'.format(correct/total))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of cnn_v3 on 10,000 test images is 0.9479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CZpgDG7G-Tmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Testing cnn_v4"
      ]
    },
    {
      "metadata": {
        "id": "pBVOcGl2-XuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9fd5ea7-472d-4a2e-e20d-a703a2f170a3"
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = cnn_v4(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of cnn_v4 on 10,000 test images is {}'.format(correct/total))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of cnn_v4 on 10,000 test images is 0.9364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RaJgwwpt-k-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Comments on test results\n",
        "1. cnn_v2 did the best\n",
        "1. cnn_v3 and cnn_v4 did worse than cnn_v2, even though cnn_v2 is much simpler model. One possible explanation lies in small number of epochs. Given more epochs cnn_v3 and cnn_v4 might have fared better."
      ]
    },
    {
      "metadata": {
        "id": "xjeEKfqTNMUl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning\n",
        "We are going to use ResNet-34 pretrained model."
      ]
    },
    {
      "metadata": {
        "id": "ckjNrNiKNGJq",
        "colab_type": "code",
        "outputId": "e2a88ad8-abb3-4d2b-9ad7-642ffbd15c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# import resnet\n",
        "from torchvision import models\n",
        "resnet = models.resnet34(pretrained=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.torch/models/resnet34-333f7ec4.pth\n",
            "100%|| 87306240/87306240 [00:02<00:00, 40265079.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kGQ8XP40ZMfR",
        "colab_type": "code",
        "outputId": "c4b59b66-f119-4d8c-f7d9-0d681b4e7e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2437
        }
      },
      "cell_type": "code",
      "source": [
        "# let us see the structure of the resnet\n",
        "resnet"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "oy4UPPRtbtfM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# resnet is made of convolution layers, which means that we could, in principle,\n",
        "# supply an image of arbitrary size. The only thing we need to change is to modify\n",
        "# number of channels of the first convolutional layer.\n",
        "# moreover, we need to modify output of the resnet to have 10 class output\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad = False\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "resnet.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtgdObqQC6bj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Training resnet based model"
      ]
    },
    {
      "metadata": {
        "id": "lM0qEE4F-V9s",
        "colab_type": "code",
        "outputId": "27bb1dfa-82a4-4938-a0d1-f997884902cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1320
        }
      },
      "cell_type": "code",
      "source": [
        "# let's use gpu's for training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "resnet_gpu = resnet.to(device)\n",
        "\n",
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(resnet_gpu.parameters(), lr=0.001)\n",
        "\n",
        "# define number of epochs, i.e. number of \n",
        "epochs = 2\n",
        "\n",
        "\n",
        "\n",
        "# training with gpu's\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    # get inputs\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # zero parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = resnet_gpu(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # printing statistics\n",
        "    running_loss += loss.item()\n",
        "    if i%200 == 199:\n",
        "      print('Epoch: {}, Batch: {} - Loss: {}'.format(epoch, i+1, running_loss/200))\n",
        "      running_loss = 0\n",
        "print('Finished Training')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch: 0, Batch: 200 - Loss: 2.1066227108240128\n",
            "Epoch: 0, Batch: 400 - Loss: 1.7568936383724212\n",
            "Epoch: 0, Batch: 600 - Loss: 1.6827304509282113\n",
            "Epoch: 0, Batch: 800 - Loss: 1.5200291097164154\n",
            "Epoch: 0, Batch: 1000 - Loss: 1.3806474950909615\n",
            "Epoch: 0, Batch: 1200 - Loss: 1.3060316662490368\n",
            "Epoch: 0, Batch: 1400 - Loss: 1.2074300256371497\n",
            "Epoch: 0, Batch: 1600 - Loss: 1.2769722911715506\n",
            "Epoch: 0, Batch: 1800 - Loss: 1.2429781539738178\n",
            "Epoch: 0, Batch: 2000 - Loss: 1.1635684995353222\n",
            "Epoch: 0, Batch: 2200 - Loss: 1.2278813475370407\n",
            "Epoch: 0, Batch: 2400 - Loss: 1.1330644063651563\n",
            "Epoch: 0, Batch: 2600 - Loss: 1.148104914277792\n",
            "Epoch: 0, Batch: 2800 - Loss: 1.1445678310096263\n",
            "Epoch: 0, Batch: 3000 - Loss: 1.077944633960724\n",
            "Epoch: 0, Batch: 3200 - Loss: 1.1754333890229463\n",
            "Epoch: 0, Batch: 3400 - Loss: 1.1131067150086165\n",
            "Epoch: 0, Batch: 3600 - Loss: 1.1573284389078617\n",
            "Epoch: 0, Batch: 3800 - Loss: 1.0432763659209012\n",
            "Epoch: 0, Batch: 4000 - Loss: 1.0630494710803031\n",
            "Epoch: 0, Batch: 4200 - Loss: 1.004766171053052\n",
            "Epoch: 0, Batch: 4400 - Loss: 0.9791001203656197\n",
            "Epoch: 0, Batch: 4600 - Loss: 1.0068244839459657\n",
            "Epoch: 0, Batch: 4800 - Loss: 0.9643149028345942\n",
            "Epoch: 0, Batch: 5000 - Loss: 0.978157471343875\n",
            "Epoch: 0, Batch: 5200 - Loss: 0.9996503990888596\n",
            "Epoch: 0, Batch: 5400 - Loss: 0.9718867879360914\n",
            "Epoch: 0, Batch: 5600 - Loss: 1.0043103943020106\n",
            "Epoch: 0, Batch: 5800 - Loss: 0.994264122992754\n",
            "Epoch: 0, Batch: 6000 - Loss: 0.9368172767758369\n",
            "Epoch: 0, Batch: 6200 - Loss: 0.9717952617257833\n",
            "Epoch: 0, Batch: 6400 - Loss: 0.980497523471713\n",
            "Epoch: 0, Batch: 6600 - Loss: 0.9654722907021642\n",
            "Epoch: 0, Batch: 6800 - Loss: 0.946624768525362\n",
            "Epoch: 0, Batch: 7000 - Loss: 0.9371829003095626\n",
            "Epoch: 0, Batch: 7200 - Loss: 0.9866652218252421\n",
            "Epoch: 0, Batch: 7400 - Loss: 0.9724373548477888\n",
            "Epoch: 1, Batch: 200 - Loss: 0.9284672279283405\n",
            "Epoch: 1, Batch: 400 - Loss: 0.9012732481583953\n",
            "Epoch: 1, Batch: 600 - Loss: 0.8900775104761124\n",
            "Epoch: 1, Batch: 800 - Loss: 0.8888467421382665\n",
            "Epoch: 1, Batch: 1000 - Loss: 0.9484075653553009\n",
            "Epoch: 1, Batch: 1200 - Loss: 0.9739402943849563\n",
            "Epoch: 1, Batch: 1400 - Loss: 0.9120552602410317\n",
            "Epoch: 1, Batch: 1600 - Loss: 0.8940777800232173\n",
            "Epoch: 1, Batch: 1800 - Loss: 0.9113859344273806\n",
            "Epoch: 1, Batch: 2000 - Loss: 0.9515913898870348\n",
            "Epoch: 1, Batch: 2200 - Loss: 0.9110637531057\n",
            "Epoch: 1, Batch: 2400 - Loss: 0.9115404204651714\n",
            "Epoch: 1, Batch: 2600 - Loss: 0.8773684898763895\n",
            "Epoch: 1, Batch: 2800 - Loss: 0.8979279246553779\n",
            "Epoch: 1, Batch: 3000 - Loss: 0.9198840823397041\n",
            "Epoch: 1, Batch: 3200 - Loss: 0.8893799241632223\n",
            "Epoch: 1, Batch: 3400 - Loss: 0.800090840794146\n",
            "Epoch: 1, Batch: 3600 - Loss: 0.9017164040356874\n",
            "Epoch: 1, Batch: 3800 - Loss: 0.9204813500121236\n",
            "Epoch: 1, Batch: 4000 - Loss: 0.8697829990833997\n",
            "Epoch: 1, Batch: 4200 - Loss: 0.9200643346458673\n",
            "Epoch: 1, Batch: 4400 - Loss: 0.8945589435100555\n",
            "Epoch: 1, Batch: 4600 - Loss: 0.8773938550800086\n",
            "Epoch: 1, Batch: 4800 - Loss: 0.9188241648674011\n",
            "Epoch: 1, Batch: 5000 - Loss: 0.8276488816365599\n",
            "Epoch: 1, Batch: 5200 - Loss: 0.8848771275952458\n",
            "Epoch: 1, Batch: 5400 - Loss: 0.84672798153013\n",
            "Epoch: 1, Batch: 5600 - Loss: 0.8677549787983299\n",
            "Epoch: 1, Batch: 5800 - Loss: 0.861587104331702\n",
            "Epoch: 1, Batch: 6000 - Loss: 0.8182175298407673\n",
            "Epoch: 1, Batch: 6200 - Loss: 0.8474248044937849\n",
            "Epoch: 1, Batch: 6400 - Loss: 0.7960738562420011\n",
            "Epoch: 1, Batch: 6600 - Loss: 0.8178904182463884\n",
            "Epoch: 1, Batch: 6800 - Loss: 0.9339515015482902\n",
            "Epoch: 1, Batch: 7000 - Loss: 0.8829244500026107\n",
            "Epoch: 1, Batch: 7200 - Loss: 0.8536504770629108\n",
            "Epoch: 1, Batch: 7400 - Loss: 0.8658680837601423\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9iZz9ITVFGCR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Testing resnet_gpu"
      ]
    },
    {
      "metadata": {
        "id": "pJ-FQmmiFQg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3caec197-ccb8-4f7d-d641-d19c4a1e9888"
      },
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_loader:\n",
        "    inputs, labels = data\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = resnet_gpu(inputs)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "print('Accuracy of resnet_gpu on 10,000 test images is {}'.format(correct/total))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of resnet_gpu on 10,000 test images is 0.7645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j0UXzkTOZNs7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Comments on testing results of resnet_gpu\n",
        "1. We have comprimised Resnet's ability to extract meaningful features by replacing the first layer.\n",
        "2. Resnet is quite complex, so we might need more epochs.\n",
        "3. However, in principle, transfer learning should work pretty well."
      ]
    }
  ]
}